{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85039cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25a4d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "color_list = [x[\"color\"] for x in plt.rcParams[\"axes.prop_cycle\"]]\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import multiprocessing\n",
    "import os\n",
    "import pickle\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c0a1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import load_mnist_binary\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_mnist_binary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcbd7da",
   "metadata": {},
   "source": [
    "# Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "763b4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2b86dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(\n",
    "    n_neighbors=5,\n",
    "    weights=\"uniform\",\n",
    "    algorithm=\"auto\",\n",
    "    leaf_size=30,\n",
    "    p=2,\n",
    "    metric=\"minkowski\",\n",
    "    metric_params=None,\n",
    "    n_jobs=-1,\n",
    ").fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bad8f747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.99\n",
      "Accuracy on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "preds_train = clf.predict(X_train)\n",
    "print(f\"Accuracy on training set: {accuracy_score(preds_train, y_train):.2f}\")\n",
    "preds_test = clf.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(preds_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9e4d3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.00\n",
      "Accuracy on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(\n",
    "    n_neighbors=1,\n",
    "    weights=\"uniform\",\n",
    "    algorithm=\"auto\",\n",
    "    leaf_size=30,\n",
    "    p=2,\n",
    "    metric=\"minkowski\",\n",
    "    metric_params=None,\n",
    "    n_jobs=-1,\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "preds_train = clf.predict(X_train)\n",
    "print(f\"Accuracy on training set: {accuracy_score(preds_train, y_train):.2f}\")\n",
    "preds_test = clf.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(preds_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eb33d9",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2d40650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1ff9699b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.00\n",
      "Accuracy on test set: 0.96\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    criterion=\"gini\",\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=\"auto\",\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=None,\n",
    "    random_state=None,\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    class_weight=None,\n",
    "    ccp_alpha=0.0,\n",
    "    max_samples=None,\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "preds_train = clf.predict(X_train)\n",
    "print(f\"Accuracy on training set: {accuracy_score(preds_train, y_train):.2f}\")\n",
    "preds_test = clf.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(preds_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e70056a",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2a9e2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "519be45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.87\n",
      "Accuracy on test set: 0.87\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(\n",
    "    penalty=\"l2\",\n",
    "    dual=False,\n",
    "    tol=0.0001,\n",
    "    C=1.0,\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=1,\n",
    "    class_weight=None,\n",
    "    random_state=None,\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=10_000,\n",
    "    multi_class=\"auto\",\n",
    "    verbose=0,\n",
    "    warm_start=False,\n",
    "    n_jobs=-1,\n",
    "    l1_ratio=None,\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "preds_train = clf.predict(X_train)\n",
    "print(f\"Accuracy on training set: {accuracy_score(preds_train, y_train):.2f}\")\n",
    "preds_test = clf.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(preds_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef5e49",
   "metadata": {},
   "source": [
    "# Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73fc2325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff9feee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.77\n",
      "Accuracy on test set: 0.77\n"
     ]
    }
   ],
   "source": [
    "clf = BernoulliNB(alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None).fit(\n",
    "    X_train, y_train\n",
    ")\n",
    "\n",
    "preds_train = clf.predict(X_train)\n",
    "print(f\"Accuracy on training set: {accuracy_score(preds_train, y_train):.2f}\")\n",
    "preds_test = clf.predict(X_test)\n",
    "print(f\"Accuracy on test set: {accuracy_score(preds_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a4ddf9",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "162ca922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25b00171",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5,5), padding=2)\n",
    "        self.conv2 = nn.Conv2d(64, 32, (5,5))\n",
    "        self.fc1   = nn.Linear(32*5*5, 256)\n",
    "        self.fc2   = nn.Linear(256, 128)\n",
    "        self.fc3   = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "860e2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = torch.tensor(X.reshape((X.shape[0], 1, 28, 28)), dtype=torch.float32)\n",
    "        self.y = torch.tensor(np.expand_dims(y, axis=1), dtype=torch.float32)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def evaluate(network, data, metric):\n",
    "    network.eval()\n",
    "    with torch.no_grad():\n",
    "        losses = torch.zeros((len(data)))\n",
    "        for idx, (x, y) in enumerate(data):\n",
    "            preds = network(x)\n",
    "            loss = metric(preds, y)\n",
    "            losses[idx] = loss\n",
    "    return losses\n",
    "\n",
    "def update(network: nn.Module, data: DataLoader, loss_fn: nn.Module, \n",
    "           opt: torch.optim.Optimizer) -> list:\n",
    "    network.train()\n",
    "    losses = torch.zeros((len(data)), requires_grad=False)\n",
    "    \n",
    "    for idx, (x, y) in enumerate(data):\n",
    "        opt.zero_grad()\n",
    "        preds = network(x)\n",
    "        loss = loss_fn(preds, y)\n",
    "        losses[idx] = loss.detach()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43d14b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MNISTDataset(X_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "test_ds = MNISTDataset(X_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, shuffle=True, drop_last=True)\n",
    "\n",
    "loss_fn = nn.functional.binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9103163",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    train_losses_ = update(model, train_dl, loss_fn, opt)\n",
    "\n",
    "    test_losses = evaluate(model, test_dl, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "494f8783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for idx, (x, y) in enumerate(train_dl):\n",
    "        preds = model(x)\n",
    "        if idx == 0:\n",
    "            ps = torch.round(preds).numpy()\n",
    "            ys = y.numpy()\n",
    "        else:\n",
    "            ps = np.append(ps, torch.round(preds).numpy())\n",
    "            ys = np.append(ys, y.numpy())\n",
    "\n",
    "acc_train = accuracy_score(ys, ps)\n",
    "print(f\"Train accuracy: {acc_train:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b9b60895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for idx, (x, y) in enumerate(test_dl):\n",
    "        preds = model(x)\n",
    "        if idx == 0:\n",
    "            ps = torch.round(preds).numpy()\n",
    "            ys = y.numpy()\n",
    "        else:\n",
    "            ps = np.append(ps, torch.round(preds).numpy())\n",
    "            ys = np.append(ys, y.numpy())\n",
    "\n",
    "acc_test = accuracy_score(ys, ps)\n",
    "print(f\"Test accuracy: {acc_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff4b49",
   "metadata": {},
   "source": [
    "# Model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c558abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.621 MB\n",
      "2621 KB\n",
      "2621440 B\n"
     ]
    }
   ],
   "source": [
    "viz_size(get_lut_size(2, [1024] * 5) * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0587976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lut_size(bits, layers):\n",
    "    single_lut_size = 2 ** bits # Size in bits\n",
    "    total_lut_size = 0\n",
    "    for num_luts in layers:\n",
    "        total_lut_size += num_luts * single_lut_size\n",
    "    return total_lut_size / 8 # Size in bytes\n",
    "\n",
    "def viz_size(size):\n",
    "    # Size is in bytes\n",
    "    print(f\"{size/1e6:.3f} MB\")\n",
    "    print(f\"{size/1e3:.0f} KB\")\n",
    "    print(f\"{size:.0f} B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace67375",
   "metadata": {},
   "source": [
    "## LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa8ad468",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.622 MB\n",
      "2622 KB\n",
      "2621952 B\n"
     ]
    }
   ],
   "source": [
    "viz_size(get_lut_size(2, [1024] * 5 + [1]) * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9585907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.168 MB\n",
      "168 KB\n",
      "168448 B\n"
     ]
    }
   ],
   "source": [
    "viz_size(get_lut_size(2, [64] * 5 + [1]) * 1024 + 32 / 8 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43c999b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.164 MB\n",
      "164 KB\n",
      "163968 B\n"
     ]
    }
   ],
   "source": [
    "viz_size(get_lut_size(10, [256] * 5 + [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71357e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.622 MB\n",
      "2622 KB\n",
      "2621952 B\n"
     ]
    }
   ],
   "source": [
    "viz_size(get_lut_size(12, [1024] * 5 + [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48ede54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.655 MB\n",
      "655 KB\n",
      "655488 B\n"
     ]
    }
   ],
   "source": [
    "viz_size(get_lut_size(10, [1024] * 5 + [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ba417e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.041 MB\n",
      "41 KB\n",
      "40992 B\n"
     ]
    }
   ],
   "source": [
    "viz_size(get_lut_size(8, [256] * 5 + [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81661fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.164 MB\n",
      "164 KB\n",
      "163872 B\n"
     ]
    }
   ],
   "source": [
    "viz_size(get_lut_size(8, [1024] * 5 + [1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7970f8d",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d5cd214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.164 MB\n",
      "1164 KB\n",
      "1163908 B\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Earlier we defined 32-bit floating point\n",
    "viz_size(pytorch_total_params * 32 / 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3394f904",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93661ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [x for x in dir(clf) if x[0] != \"_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70f76b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming 32-bit floats and ints everywhere\n",
    "z = 0\n",
    "\n",
    "for m in methods:\n",
    "    tp = type(getattr(clf, m))\n",
    "    if tp == float:\n",
    "        z += (32 / 8)\n",
    "    elif tp == np.ndarray:\n",
    "        z += len(getattr(clf, m).flatten()) * (32 / 8)\n",
    "    elif tp == int:\n",
    "        z += (32 / 8)\n",
    "    else:\n",
    "        pass # We do not bother for bools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155d6f7",
   "metadata": {},
   "source": [
    "Sklearn uses 64-bit floats, but for the Thesis we will use 32 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b48f609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003 MB\n",
      "3 KB\n",
      "3180 B\n"
     ]
    }
   ],
   "source": [
    "viz_size(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c44fe",
   "metadata": {},
   "source": [
    "# Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e46ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [x for x in dir(clf) if x[0] != \"_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4aaef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assuming 32-bit floats and ints everywhere\n",
    "z = 0\n",
    "\n",
    "for m in methods:\n",
    "    tp = type(getattr(clf, m))\n",
    "    if tp == float:\n",
    "        z += (32 / 8)\n",
    "    elif tp == np.ndarray:\n",
    "        z += len(getattr(clf, m).flatten()) * (32 / 8)\n",
    "    elif tp == int:\n",
    "        z += (32 / 8)\n",
    "    else:\n",
    "        pass # We do not bother for bools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "513927af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016 MB\n",
      "16 KB\n",
      "15724 B\n"
     ]
    }
   ],
   "source": [
    "viz_size(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1021d",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "377634da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array-based representation of a binary decision tree.\n",
      "\n",
      "    The binary tree is represented as a number of parallel arrays. The i-th\n",
      "    element of each array holds information about the node `i`. Node 0 is the\n",
      "    tree's root. You can find a detailed description of all arrays in\n",
      "    `_tree.pxd`. NOTE: Some of the arrays only apply to either leaves or split\n",
      "    nodes, resp. In this case the values of nodes of the other type are\n",
      "    arbitrary!\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    node_count : int\n",
      "        The number of nodes (internal nodes + leaves) in the tree.\n",
      "\n",
      "    capacity : int\n",
      "        The current capacity (i.e., size) of the arrays, which is at least as\n",
      "        great as `node_count`.\n",
      "\n",
      "    max_depth : int\n",
      "        The depth of the tree, i.e. the maximum depth of its leaves.\n",
      "\n",
      "    children_left : array of int, shape [node_count]\n",
      "        children_left[i] holds the node id of the left child of node i.\n",
      "        For leaves, children_left[i] == TREE_LEAF. Otherwise,\n",
      "        children_left[i] > i. This child handles the case where\n",
      "        X[:, feature[i]] <= threshold[i].\n",
      "\n",
      "    children_right : array of int, shape [node_count]\n",
      "        children_right[i] holds the node id of the right child of node i.\n",
      "        For leaves, children_right[i] == TREE_LEAF. Otherwise,\n",
      "        children_right[i] > i. This child handles the case where\n",
      "        X[:, feature[i]] > threshold[i].\n",
      "\n",
      "    feature : array of int, shape [node_count]\n",
      "        feature[i] holds the feature to split on, for the internal node i.\n",
      "\n",
      "    threshold : array of double, shape [node_count]\n",
      "        threshold[i] holds the threshold for the internal node i.\n",
      "\n",
      "    value : array of double, shape [node_count, n_outputs, max_n_classes]\n",
      "        Contains the constant prediction value of each node.\n",
      "\n",
      "    impurity : array of double, shape [node_count]\n",
      "        impurity[i] holds the impurity (i.e., the value of the splitting\n",
      "        criterion) at node i.\n",
      "\n",
      "    n_node_samples : array of int, shape [node_count]\n",
      "        n_node_samples[i] holds the number of training samples reaching node i.\n",
      "\n",
      "    weighted_n_node_samples : array of int, shape [node_count]\n",
      "        weighted_n_node_samples[i] holds the weighted number of training samples\n",
      "        reaching node i.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(clf.estimators_[0].tree_.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4804dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 0\n",
    "\n",
    "for est in clf.estimators_:\n",
    "    tr = est.tree_\n",
    "    methods = [x for x in dir(tr) if x[0] != \"_\"]\n",
    "    for m in methods:\n",
    "        tp = type(getattr(tr, m))\n",
    "        if tp == float:\n",
    "            z += (32 / 8)\n",
    "        elif tp == np.ndarray:\n",
    "            z += len(getattr(tr, m).flatten()) * (32 / 8)\n",
    "        elif tp == int:\n",
    "            z += (32 / 8)\n",
    "        else:\n",
    "            pass # We do not bother for bools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa9c78ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.797 MB\n",
      "3797 KB\n",
      "3797488 B\n"
     ]
    }
   ],
   "source": [
    "viz_size(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
