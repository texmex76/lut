{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26631f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "color_list = [x[\"color\"] for x in plt.rcParams[\"axes.prop_cycle\"]]\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import multiprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa4e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lut import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d890273e",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5119df91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(n_samples=10_000, pca=False, n_components=8):\n",
    "    data = np.load(\"data/lut/MNIST.npz\", allow_pickle=True)\n",
    "    X_ = data[\"X\"]\n",
    "    y_ = data[\"y\"]\n",
    "    \n",
    "    assert n_samples <= 70_000, f\"Full data available only has 70_000 samples\"\n",
    "\n",
    "    if pca:\n",
    "        pca_ = PCA(n_components=n_components)\n",
    "        X_ = pca_.fit_transform(X_)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_tf = scaler.fit_transform(X_)\n",
    "\n",
    "    X = (X_tf > 0.5).astype(bool)\n",
    "    y = (y_ == 0) | (y_ == 1) | (y_ == 2) | (y_ == 3) | (y_ == 4)\n",
    "\n",
    "    X, y = shuffle(X, y, n_samples=n_samples, random_state=100)\n",
    "\n",
    "    X_train, X_test, y_train, y_test, = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=False\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_mnist(n_samples=30_000, pca=False, n_components=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073a65a3",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5cab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 79 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf8303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "hidden_layers = [1024] * 10\n",
    "lut = Lut(\n",
    "    bits=[2] * (len(hidden_layers) + 1),\n",
    "    hidden_layers=hidden_layers,\n",
    "    make_aig=False,\n",
    "    discard_randoms=False,\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "preds_train = lut.train(X_train, y_train)\n",
    "preds_test = lut.predict(X_test)\n",
    "print(\n",
    "    f\"Accuracy on training set (no major): {accuracy_score(preds_train, y_train):.2f}\"\n",
    ")\n",
    "print(f\"Accuracy on test set (no major): {accuracy_score(preds_test, y_test):.2f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# preds_train = lut.predict(X_train, majority_vote=True)\n",
    "# preds_test = lut.predict(X_test, majority_vote=True)\n",
    "# print(f\"Accuracy on training set (major): {accuracy_score(preds_train, y_train):.2f}\")\n",
    "# print(f\"Accuracy on test set (major): {accuracy_score(preds_test, y_test):.2f}\")\n",
    "\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_rnd = [\n",
    "    np.any(lut.rnd_arr_[i], axis=1).sum() / lut.rnd_arr_[i].shape[0]\n",
    "    for i in range(len(lut.rnd_arr_) - 1)\n",
    "]\n",
    "\n",
    "frac_not_used = (\n",
    "    np.array(\n",
    "        [\n",
    "            len(\n",
    "                np.where(\n",
    "                    np.bincount(\n",
    "                        np.hstack((np.unique(lut.cols_arr_[i]), list(range(1024))))\n",
    "                    )\n",
    "                    != 2\n",
    "                )[0]\n",
    "            )\n",
    "            for i in range(1, len(hidden_layers))\n",
    "        ]\n",
    "    )\n",
    "    / 1024\n",
    ")\n",
    "frac_not_used_0 = (\n",
    "    len(\n",
    "        np.where(\n",
    "            np.bincount(np.hstack((np.unique(lut.cols_arr_[0]), list(range(784))))) != 2\n",
    "        )[0]\n",
    "    )\n",
    "    / 784\n",
    ")\n",
    "frac_not_used = np.insert(frac_not_used, 0, frac_not_used_0)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax = axs[0]\n",
    "ax.plot(np.arange(1, len(frac_rnd) + 1), frac_rnd, \"o-\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_title(\"Fraction random\")\n",
    "\n",
    "ax = axs[1]\n",
    "ax.plot(np.arange(1, len(frac_rnd) + 1), frac_not_used, \"o-\")\n",
    "ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "ax.set_title(\"Fraction not used\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66170571",
   "metadata": {},
   "source": [
    "## Combining many luts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = [1024] * 10\n",
    "\n",
    "preds_train = []\n",
    "preds_test = []\n",
    "luts = []\n",
    "\n",
    "for _ in tqdm(range(10)):\n",
    "    lut = Lut(\n",
    "        bits=[2] * (len(hidden_layers) + 1),\n",
    "        hidden_layers=hidden_layers,\n",
    "        make_aig=False,\n",
    "        discard_randoms=False,\n",
    "        patience=10,\n",
    "        verbose=False\n",
    "    )\n",
    "    luts.append(lut)\n",
    "    preds_train.append(lut.train(X_train, y_train))\n",
    "    preds_test.append(lut.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e149fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = np.array(preds_train).astype(int)\n",
    "train_[train_ == 0] = -1\n",
    "train_ = train_.sum(0)\n",
    "\n",
    "cumul_preds_train = np.zeros_like(train_, dtype=bool)\n",
    "cumul_preds_train[train_ >= 0] = True\n",
    "\n",
    "print(f\"Accuracy on training set: {accuracy_score(cumul_preds_train, y_train):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b98275",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = np.array(preds_test).astype(int)\n",
    "test_[test_ == 0] = -1\n",
    "test_ = test_.sum(0)\n",
    "\n",
    "cumul_preds_test = np.zeros_like(test_, dtype=bool)\n",
    "cumul_preds_test[test_ >= 0] = True\n",
    "\n",
    "print(f\"Accuracy on testing set: {accuracy_score(cumul_preds_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3205b17f",
   "metadata": {},
   "source": [
    "## Visualizing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ac1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 4\n",
    "idxs = np.random.randint(low=0, high=X_train.shape[0], size=size ** 2)\n",
    "\n",
    "enlarge = 2\n",
    "fig, axs = plt.subplots(size, size, figsize=(size * enlarge, size * enlarge))\n",
    "\n",
    "for idx, ax in enumerate(axs.flatten()):\n",
    "    ax.imshow(X_train[idxs[idx]].reshape((28, 28)))\n",
    "    lbl = int(y_train[idxs[idx]])\n",
    "    if lbl:\n",
    "        ax.set_title(f\"Label 1 (0-4)\")\n",
    "    else:\n",
    "        ax.set_title(f\"Label 0 (5-9)\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcbb79f",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299189d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,))\n",
    "clf.fit(X_train, y_train)\n",
    "preds_mlp_train = clf.predict(X_train)\n",
    "preds_mlp_test = clf.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy on training set: {accuracy_score(preds_mlp_train, y_train):.2f}%\")\n",
    "print(f\"Accuracy on test set: {accuracy_score(preds_mlp_test, y_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20be2c5f",
   "metadata": {},
   "source": [
    "### Majority Vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd18158",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_arr = [4, 5, 6, 7, 8]\n",
    "majority_arr = [True, False]\n",
    "acc_train_majority = []\n",
    "acc_train_no_majority = []\n",
    "acc_test_majority = []\n",
    "acc_test_no_majority = []\n",
    "for bit in bit_arr:\n",
    "    for majority in majority_arr:\n",
    "        lut = Lut(bits=[bit] * 4, hidden_layers=[1000] * 3, majority_vote=majority)\n",
    "        preds_train = lut.train(X_train, y_train)\n",
    "        preds_test = lut.predict(X_test)\n",
    "\n",
    "        if majority:\n",
    "            acc_train_majority.append(accuracy_score(preds_train, y_train))\n",
    "            acc_test_majority.append(accuracy_score(preds_test, y_test))\n",
    "        else:\n",
    "            acc_train_no_majority.append(accuracy_score(preds_train, y_train))\n",
    "            acc_test_no_majority.append(accuracy_score(preds_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b33e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_majority, acc_train_no_majority, acc_test_majority, acc_test_no_majority"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33ce948",
   "metadata": {},
   "source": [
    "### Discard bad Luts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33beb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut = Lut(bits=[8] * 4, hidden_layers=[100] * 3, majority_vote=False)\n",
    "preds_train = lut.train(X_train, y_train)\n",
    "preds_test = lut.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy on training set: {accuracy_score(preds_train, y_train):.2f}%\")\n",
    "print(f\"Accuracy on test set: {accuracy_score(preds_test, y_test):.2f}%\")\n",
    "\n",
    "acc = lut.get_accuracies_per_layer(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, len(acc) - 1, figsize=(9, 3))\n",
    "for idx, ax in enumerate(axs):\n",
    "    ax.hist(acc[idx], bins=20)\n",
    "    xrange = ax.get_xlim()[1] - ax.get_xlim()[0]\n",
    "    yrange = ax.get_ylim()[1] - ax.get_ylim()[0]\n",
    "    ax.text(ax.get_xlim()[0] + xrange * 0.1, ax.get_ylim()[0] + yrange * 0.8, f\"$\\mu=${np.mean(acc[idx]):.2f}\")\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax.set_title(f\"Test accuracies for\\nhidden layer {idx + 1},\\n{len(acc[idx])} luts\")\n",
    "    ax.set_xlabel(\"Accuracy\")\n",
    "    ax.set_ylabel(\"Occurrence\")\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68342955",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_arr = [4, 5, 6, 7, 8]\n",
    "discard_arr = [True, False]\n",
    "acc_train_discard = []\n",
    "acc_train_no_discard = []\n",
    "acc_test_discard = []\n",
    "acc_test_no_discard = []\n",
    "\n",
    "for bit in bit_arr:\n",
    "    tmp_acc_train_discard = []\n",
    "    tmp_acc_train_no_discard = []\n",
    "    tmp_acc_test_discard = []\n",
    "    tmp_acc_test_no_discard = []\n",
    "    for _ in range(10):\n",
    "        for discard in discard_arr:\n",
    "            lut = Lut(\n",
    "                bits=[bit] * 4,\n",
    "                hidden_layers=[100] * 3,\n",
    "                majority_vote=False,\n",
    "                discard_bad_luts=discard,\n",
    "                des_acc=[0.63, 0.83, 0.86],\n",
    "                discard_num = 10,\n",
    "                patience=10\n",
    "            )\n",
    "            preds_train = lut.train(X_train, y_train)\n",
    "            preds_test = lut.predict(X_test)\n",
    "\n",
    "            if discard:\n",
    "                tmp_acc_train_discard.append(accuracy_score(preds_train, y_train))\n",
    "                tmp_acc_test_discard.append(accuracy_score(preds_test, y_test))\n",
    "            else:\n",
    "                tmp_acc_train_no_discard.append(accuracy_score(preds_train, y_train))\n",
    "                tmp_acc_test_no_discard.append(accuracy_score(preds_test, y_test))\n",
    "\n",
    "    acc_train_discard.append(tmp_acc_train_discard)\n",
    "    acc_train_no_discard.append(tmp_acc_train_no_discard)\n",
    "    acc_test_discard.append(tmp_acc_test_discard)\n",
    "    acc_test_no_discard.append(tmp_acc_test_no_discard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de3052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
