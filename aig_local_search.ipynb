{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d35a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import random\n",
    "import uuid\n",
    "from graphviz import Source\n",
    "from itertools import chain\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9514f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.id = uuid.uuid1()\n",
    "        pass\n",
    "\n",
    "\n",
    "class InputNode(Node):\n",
    "    def __init__(self, var_id):\n",
    "        super().__init__()\n",
    "        self.var_id = var_id\n",
    "        self.children = []\n",
    "        self.loc = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"InputNode at {self.loc}\"\n",
    "\n",
    "class AndNode(Node):\n",
    "    def __init__(self, var_id):\n",
    "        super().__init__()\n",
    "        self.var_id = var_id\n",
    "        self.is_output = False\n",
    "        self.parents = []\n",
    "        self.children = []\n",
    "        self.loc = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"AndNode at {self.loc}\"\n",
    "        \n",
    "class OutputNode(Node):\n",
    "    def __init__(self, var_id):\n",
    "        super().__init__()\n",
    "        self.var_id = var_id\n",
    "        self.is_output = False\n",
    "        self.parents = []\n",
    "        self.children = []\n",
    "        self.loc = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"OutputNode at {self.loc}\"\n",
    "\n",
    "\n",
    "class NodeNetwork:\n",
    "    def __init__(self, num_inputs, hidden_layers, num_outputs):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.num_outputs = num_outputs\n",
    "        self.max_var_idx = 0\n",
    "        self.nodes_ = []\n",
    "\n",
    "        # Input nodes\n",
    "        input_nodes = []\n",
    "        for i in range(num_inputs):\n",
    "            self.max_var_idx += 1\n",
    "            inp_node = InputNode(self.max_var_idx)\n",
    "            inp_node.loc = (0, i)\n",
    "            input_nodes.append(inp_node)\n",
    "        self.nodes_.append(input_nodes)\n",
    "\n",
    "        # And nodes\n",
    "        for i in range(1, len(self.hidden_layers) + 1):\n",
    "            # i is column index\n",
    "            # We start at 1 since the 0th row is the input row\n",
    "            and_nodes = []\n",
    "            for j in range(self.hidden_layers[i - 1]):\n",
    "                # Since we shift i with 1, we have to shift it back here\n",
    "                self.max_var_idx += 1\n",
    "                and_node = AndNode(self.max_var_idx)\n",
    "                and_node.loc = (i, j)\n",
    "                while len(and_node.parents) < 2:\n",
    "                    candidate_parent_idx = np.random.randint(\n",
    "                        low=0, high=len(self.nodes_[-1])\n",
    "                    )\n",
    "                    candidate_parent = self.nodes_[-1][candidate_parent_idx]\n",
    "                    if candidate_parent.loc not in and_node.parents:\n",
    "                        and_node.parents.append(candidate_parent.loc)\n",
    "                        candidate_parent.children.append(and_node.loc)\n",
    "                and_node.negate_0 = random.choice([True, False])\n",
    "                and_node.negate_1 = random.choice([True, False])\n",
    "\n",
    "                and_nodes.append(and_node)\n",
    "            self.nodes_.append(and_nodes)\n",
    "\n",
    "        # Output nodes\n",
    "        output_nodes = []\n",
    "        for i in range(num_outputs):\n",
    "            self.max_var_idx += 1\n",
    "            output_node = OutputNode(self.max_var_idx)\n",
    "            output_node.loc = (len(self.hidden_layers) + 1, i)\n",
    "            output_node.is_output = True\n",
    "\n",
    "            while len(output_node.parents) < 2:\n",
    "                candidate_parent_idx = np.random.randint(\n",
    "                    low=0, high=len(self.nodes_[-1])\n",
    "                )\n",
    "                candidate_parent = self.nodes_[-1][candidate_parent_idx]\n",
    "                if candidate_parent.loc not in output_node.parents:\n",
    "                    output_node.parents.append(candidate_parent.loc)\n",
    "                    candidate_parent.children.append(output_node.loc)\n",
    "            output_node.negate_0 = random.choice([True, False])\n",
    "            output_node.negate_1 = random.choice([True, False])\n",
    "\n",
    "            output_nodes.append(output_node)\n",
    "        self.nodes_.append(output_nodes)\n",
    "\n",
    "    def create_aag_repr_(self):\n",
    "        # File header\n",
    "        out_str = f\"aag {self.max_var_idx} {self.num_inputs} 0 {self.num_outputs} {sum(self.hidden_layers) + self.num_outputs}\\n\"\n",
    "\n",
    "        # Input nodes\n",
    "        for node in self.nodes_[0]:\n",
    "            out_str += f\"{node.var_id * 2}\\n\"\n",
    "\n",
    "        # Output nodes\n",
    "        for node in self.nodes_[-1]:\n",
    "            out_str += f\"{node.var_id * 2}\\n\"\n",
    "\n",
    "        for i in range(len(self.nodes_)):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            for upper_node in self.nodes_[i]:\n",
    "                idx00 = upper_node.parents[0][0]\n",
    "                idx01 = upper_node.parents[0][1]\n",
    "                idx10 = upper_node.parents[1][0]\n",
    "                idx11 = upper_node.parents[1][1]\n",
    "                p0 = f\"{(self.nodes_[idx00][idx01].var_id * 2) + upper_node.negate_0}\"\n",
    "                p1 = f\"{(self.nodes_[idx10][idx11].var_id * 2) + upper_node.negate_1}\"\n",
    "                out_str += f\"{2 * upper_node.var_id} {p0} {p1}\\n\"\n",
    "\n",
    "        return out_str\n",
    "\n",
    "    def export_to_aag(self, path):\n",
    "        out_str = self.create_aag_repr_()\n",
    "        with open(path, \"w\") as f:\n",
    "            f.write(out_str)\n",
    "\n",
    "    def viz(self):\n",
    "        self.export_to_aag(\"tmp/tmp_aig.aag\")\n",
    "        dot = subprocess.check_output([\"aiger/aigtodot\", \"tmp/tmp_aig.aag\"])\n",
    "        s = Source(dot.decode(\"utf-8\"), filename=\"test\", format=\"png\")\n",
    "        os.remove(\"tmp/tmp_aig.aag\")\n",
    "        return s\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert X.dtype == \"bool\", f\"Array has to be of dtype bool\"\n",
    "        stim_str = \"\"\n",
    "        for x in X:\n",
    "            for char in x:\n",
    "                stim_str += f\"{char:d}\"\n",
    "            stim_str += \"\\n\"\n",
    "        stim_str += \".\"\n",
    "\n",
    "        with open(\"tmp/stim\", \"w\") as f:\n",
    "            f.write(stim_str)\n",
    "        self.export_to_aag(\"tmp/tmp_aig.aag\")\n",
    "\n",
    "        out = subprocess.check_output([\"aiger/aigsim\", \"tmp/tmp_aig.aag\", \"tmp/stim\"])\n",
    "        out = re.sub(\"Trace is a witness.+\", \"\", out.decode(\"utf-8\"))\n",
    "        out = out[1:].replace(\"\\n\", \"\")\n",
    "        out = out[:-1].split(\"  \")\n",
    "        preds = np.array([bool(int(x[-1])) for x in out])\n",
    "\n",
    "        os.remove(\"tmp/stim\")\n",
    "        os.remove(\"tmp/tmp_aig.aag\")\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(n_samples=10_000, pca=False, n_components=8):\n",
    "    data = np.load(\"data/lut/MNIST.npz\", allow_pickle=True)\n",
    "    X_ = data[\"X\"]\n",
    "    y_ = data[\"y\"]\n",
    "    \n",
    "    assert n_samples <= 70_000, f\"Full data available only has 70_000 samples\"\n",
    "\n",
    "    if pca:\n",
    "        pca_ = PCA(n_components=n_components)\n",
    "        X_ = pca_.fit_transform(X_)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_tf = scaler.fit_transform(X_)\n",
    "\n",
    "    X = (X_tf > 0.5).astype(bool)\n",
    "    y = (y_ == 0) | (y_ == 1) | (y_ == 2) | (y_ == 3) | (y_ == 4)\n",
    "\n",
    "    X, y = shuffle(X, y, n_samples=n_samples, random_state=100)\n",
    "\n",
    "    X_train, X_test, y_train, y_test, = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=False\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_mnist(n_samples=10_000, pca=True, n_components=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NodeNetwork(8, [8, 8, 8, 8], 1)\n",
    "# nn = NodeNetwork(784, [784, 784, 784], 1)\n",
    "\n",
    "preds_train = nn.predict(X_train)\n",
    "preds_test = nn.predict(X_test)\n",
    "acc_train = accuracy_score(preds_train, y_train)\n",
    "acc_test = accuracy_score(preds_test, y_test)\n",
    "print(f\"Accuracy on training set: {acc_train:.2f}%\")\n",
    "print(f\"Accuracy on test set: {acc_test:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb29504",
   "metadata": {},
   "source": [
    "## MLP performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b683dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,))\n",
    "clf.fit(X_train, y_train)\n",
    "preds_mlp_train = clf.predict(X_train)\n",
    "preds_mlp_test = clf.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy on training set: {accuracy_score(preds_mlp_train, y_train):.2f}%\")\n",
    "print(f\"Accuracy on test set: {accuracy_score(preds_mlp_test, y_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa98e82e",
   "metadata": {},
   "source": [
    "## AIG local search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db7d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47391543",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NodeNetwork(8, [8, 8, 8, 8], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69539cc7",
   "metadata": {},
   "source": [
    "TODOs:\n",
    "- [x] Prevent from 2 parents being the same\n",
    "- Traverse graph downwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445a4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NodeNetwork(8, [16, 16, 16, 16], 1)\n",
    "\n",
    "acc_train = 0\n",
    "iteration = 0\n",
    "acc_hist = []\n",
    "\n",
    "w = widgets.HTML(\n",
    "    value=f\"Iteration {iteration} Accuracy: {acc_train_best}\",\n",
    "    placeholder=\"Iteration progress\",\n",
    "    description=\"\",\n",
    ")\n",
    "display(w)\n",
    "\n",
    "while True:\n",
    "    iteration += 1\n",
    "    successor_candidates = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(len(list(chain(*nn.nodes_[1:])))):\n",
    "        nn_new = copy.deepcopy(nn)\n",
    "        and_node = list(chain(*nn_new.nodes_[1:]))[i]\n",
    "        # Get new parent\n",
    "        if len(nn_new.nodes_[and_node.loc[0] - 1]) > 2:\n",
    "            old_parent_loc = and_node.parents.pop(random.choice([0, 1]))\n",
    "            old_parent = nn_new.nodes_[old_parent_loc[0]][old_parent_loc[1]]\n",
    "            _ = old_parent.children.pop(old_parent.children.index(and_node.loc))\n",
    "            new_parent = random.choice(nn_new.nodes_[and_node.loc[0] - 1])\n",
    "            # To prevent from changing nothing or having 2 identical parents\n",
    "            while (new_parent.loc == old_parent_loc) or (new_parent.loc in and_node.parents):\n",
    "                new_parent = random.choice(nn_new.nodes_[and_node.loc[0] - 1])\n",
    "            and_node.parents.insert(0, new_parent.loc)\n",
    "            new_parent.children.append(and_node.loc)\n",
    "        # Change polarity\n",
    "        and_node.negate_0 = random.choice([True, False])\n",
    "        and_node.negate_1 = random.choice([True, False])\n",
    "        successor_candidates.append(nn_new)\n",
    "        \n",
    "    for candidate in successor_candidates:\n",
    "        preds_train = candidate.predict(X_train)\n",
    "        acc_train = accuracy_score(preds_train, y_train)\n",
    "        accuracies.append(acc_train)\n",
    "        \n",
    "    acc_train_best = max(accuracies)\n",
    "    acc_hist.append(acc_train_best)\n",
    "        \n",
    "    \n",
    "    if acc_train_best > acc_train:\n",
    "        acc_train = acc_train_best\n",
    "        nn = copy.deepcopy(successor_candidates[accuracies.index(acc_train_best)])\n",
    "#     else:\n",
    "#         break\n",
    "        \n",
    "    w.value = f\"Iteration {iteration} Accuracy: {acc_train_best}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b5eed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(acc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.viz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c1b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = nn.predict(X_test)\n",
    "acc_test = accuracy_score(preds_test, y_test)\n",
    "print(f\"Accuracy on test set: {acc_test:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
