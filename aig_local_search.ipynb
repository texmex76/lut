{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d35a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import random\n",
    "import uuid\n",
    "from graphviz import Source\n",
    "from itertools import chain\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9514f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.id = uuid.uuid1()\n",
    "        pass\n",
    "\n",
    "\n",
    "class InputNode(Node):\n",
    "    def __init__(self, var_id):\n",
    "        super().__init__()\n",
    "        self.var_id = var_id\n",
    "        self.children = []\n",
    "        self.loc = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"InputNode at {self.loc}\"\n",
    "\n",
    "class AndNode(Node):\n",
    "    def __init__(self, var_id):\n",
    "        super().__init__()\n",
    "        self.var_id = var_id\n",
    "        self.is_output = False\n",
    "        self.parents = []\n",
    "        self.children = []\n",
    "        self.loc = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"AndNode at {self.loc}\"\n",
    "        \n",
    "class OutputNode(Node):\n",
    "    def __init__(self, var_id):\n",
    "        super().__init__()\n",
    "        self.var_id = var_id\n",
    "        self.is_output = False\n",
    "        self.parents = []\n",
    "        self.children = []\n",
    "        self.loc = None\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"OutputNode at {self.loc}\"\n",
    "\n",
    "\n",
    "class NodeNetwork:\n",
    "    def __init__(self, num_inputs, hidden_layers, num_outputs):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.num_outputs = num_outputs\n",
    "        self.max_var_idx = 0\n",
    "        self.nodes_ = []\n",
    "\n",
    "        # Input nodes\n",
    "        input_nodes = []\n",
    "        for i in range(num_inputs):\n",
    "            self.max_var_idx += 1\n",
    "            inp_node = InputNode(self.max_var_idx)\n",
    "            inp_node.loc = (0, i)\n",
    "            input_nodes.append(inp_node)\n",
    "        self.nodes_.append(input_nodes)\n",
    "\n",
    "        # And nodes\n",
    "        for i in range(1, len(self.hidden_layers) + 1):\n",
    "            # i is column index\n",
    "            # We start at 1 since the 0th row is the input row\n",
    "            and_nodes = []\n",
    "            for j in range(self.hidden_layers[i - 1]):\n",
    "                # Since we shift i with 1, we have to shift it back here\n",
    "                self.max_var_idx += 1\n",
    "                and_node = AndNode(self.max_var_idx)\n",
    "                and_node.loc = (i, j)\n",
    "                while len(and_node.parents) < 2:\n",
    "                    candidate_parent_idx = np.random.randint(\n",
    "                        low=0, high=len(self.nodes_[-1])\n",
    "                    )\n",
    "                    candidate_parent = self.nodes_[-1][candidate_parent_idx]\n",
    "                    if candidate_parent.loc not in and_node.parents:\n",
    "                        and_node.parents.append(candidate_parent.loc)\n",
    "                        candidate_parent.children.append(and_node.loc)\n",
    "                and_node.negate_0 = random.choice([True, False])\n",
    "                and_node.negate_1 = random.choice([True, False])\n",
    "\n",
    "                and_nodes.append(and_node)\n",
    "            self.nodes_.append(and_nodes)\n",
    "\n",
    "        # Output nodes\n",
    "        output_nodes = []\n",
    "        for i in range(num_outputs):\n",
    "            self.max_var_idx += 1\n",
    "            output_node = OutputNode(self.max_var_idx)\n",
    "            output_node.loc = (len(self.hidden_layers) + 1, i)\n",
    "            output_node.is_output = True\n",
    "\n",
    "            while len(output_node.parents) < 2:\n",
    "                candidate_parent_idx = np.random.randint(\n",
    "                    low=0, high=len(self.nodes_[-1])\n",
    "                )\n",
    "                candidate_parent = self.nodes_[-1][candidate_parent_idx]\n",
    "                if candidate_parent.loc not in output_node.parents:\n",
    "                    output_node.parents.append(candidate_parent.loc)\n",
    "                    candidate_parent.children.append(output_node.loc)\n",
    "            output_node.negate_0 = random.choice([True, False])\n",
    "            output_node.negate_1 = random.choice([True, False])\n",
    "\n",
    "            output_nodes.append(output_node)\n",
    "        self.nodes_.append(output_nodes)\n",
    "\n",
    "    def create_aag_repr_(self):\n",
    "        # File header\n",
    "        out_str = f\"aag {self.max_var_idx} {self.num_inputs} 0 {self.num_outputs} {sum(self.hidden_layers) + self.num_outputs}\\n\"\n",
    "\n",
    "        # Input nodes\n",
    "        for node in self.nodes_[0]:\n",
    "            out_str += f\"{node.var_id * 2}\\n\"\n",
    "\n",
    "        # Output nodes\n",
    "        for node in self.nodes_[-1]:\n",
    "            out_str += f\"{node.var_id * 2}\\n\"\n",
    "\n",
    "        for i in range(len(self.nodes_)):\n",
    "            if i == 0:\n",
    "                continue\n",
    "            for upper_node in self.nodes_[i]:\n",
    "                idx00 = upper_node.parents[0][0]\n",
    "                idx01 = upper_node.parents[0][1]\n",
    "                idx10 = upper_node.parents[1][0]\n",
    "                idx11 = upper_node.parents[1][1]\n",
    "                p0 = f\"{(self.nodes_[idx00][idx01].var_id * 2) + upper_node.negate_0}\"\n",
    "                p1 = f\"{(self.nodes_[idx10][idx11].var_id * 2) + upper_node.negate_1}\"\n",
    "                out_str += f\"{2 * upper_node.var_id} {p0} {p1}\\n\"\n",
    "\n",
    "        return out_str\n",
    "    \n",
    "    def create_aag_repr_pruned(self):\n",
    "        locs = get_active_nodes(self)\n",
    "        # File header\n",
    "        out_str = f\"aag {self.max_var_idx} {self.num_inputs} 0 {self.num_outputs} {len(locs)}\\n\"\n",
    "\n",
    "        # Input nodes\n",
    "        for node in self.nodes_[0]:\n",
    "            out_str += f\"{node.var_id * 2}\\n\"\n",
    "\n",
    "        # Output nodes\n",
    "        for node in self.nodes_[-1]:\n",
    "            out_str += f\"{node.var_id * 2}\\n\"\n",
    "\n",
    "        for loc in locs:\n",
    "            upper_node = self.nodes_[loc[0]][loc[1]]\n",
    "            idx00 = upper_node.parents[0][0]\n",
    "            idx01 = upper_node.parents[0][1]\n",
    "            idx10 = upper_node.parents[1][0]\n",
    "            idx11 = upper_node.parents[1][1]\n",
    "            p0 = f\"{(self.nodes_[idx00][idx01].var_id * 2) + upper_node.negate_0}\"\n",
    "            p1 = f\"{(self.nodes_[idx10][idx11].var_id * 2) + upper_node.negate_1}\"\n",
    "            out_str += f\"{2 * upper_node.var_id} {p0} {p1}\\n\"\n",
    "\n",
    "        return out_str\n",
    "\n",
    "    def export_to_aag(self, path, pruned=False):\n",
    "        if pruned:\n",
    "            out_str = self.create_aag_repr_pruned()\n",
    "        else:\n",
    "            out_str = self.create_aag_repr_()\n",
    "        with open(path, \"w\") as f:\n",
    "            f.write(out_str)\n",
    "\n",
    "    def viz(self, pruned=False):\n",
    "        self.export_to_aag(\"tmp/tmp_aig.aag\", pruned=pruned)\n",
    "        dot = subprocess.check_output([\"aiger/aigtodot\", \"tmp/tmp_aig.aag\"])\n",
    "        s = Source(dot.decode(\"utf-8\"), filename=\"test\", format=\"png\")\n",
    "        os.remove(\"tmp/tmp_aig.aag\")\n",
    "        return s\n",
    "\n",
    "    def predict(self, X):\n",
    "        assert X.dtype == \"bool\", f\"Array has to be of dtype bool\"\n",
    "        stim_str = \"\"\n",
    "        for x in X:\n",
    "            for char in x:\n",
    "                stim_str += f\"{char:d}\"\n",
    "            stim_str += \"\\n\"\n",
    "        stim_str += \".\"\n",
    "\n",
    "        tmp_id = str(uuid.uuid1())\n",
    "        stim_path = \"tmp/stim-\" + tmp_id\n",
    "        aag_path = \"tmp/tmp_aig-\" + tmp_id + \".aag\"\n",
    "        \n",
    "        with open(stim_path, \"w\") as f:\n",
    "            f.write(stim_str)\n",
    "        self.export_to_aag(aag_path)\n",
    "\n",
    "        out = subprocess.check_output([\"aiger/aigsim\", aag_path, stim_path])\n",
    "        out = re.sub(\"Trace is a witness.+\", \"\", out.decode(\"utf-8\"))\n",
    "        out = out[1:].replace(\"\\n\", \"\")\n",
    "        out = out[:-1].split(\"  \")\n",
    "        preds = np.array([bool(int(x[-1])) for x in out])\n",
    "\n",
    "        os.remove(stim_path)\n",
    "        os.remove(aag_path)\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(n_samples=10_000, pca=False, n_components=8):\n",
    "    data = np.load(\"data/lut/MNIST.npz\", allow_pickle=True)\n",
    "    X_ = data[\"X\"]\n",
    "    y_ = data[\"y\"]\n",
    "    \n",
    "    assert n_samples <= 70_000, f\"Full data available only has 70_000 samples\"\n",
    "\n",
    "    if pca:\n",
    "        pca_ = PCA(n_components=n_components)\n",
    "        X_ = pca_.fit_transform(X_)\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_tf = scaler.fit_transform(X_)\n",
    "\n",
    "    X = (X_tf > 0.5).astype(bool)\n",
    "    y = (y_ == 0) | (y_ == 1) | (y_ == 2) | (y_ == 3) | (y_ == 4)\n",
    "\n",
    "    X, y = shuffle(X, y, n_samples=n_samples, random_state=100)\n",
    "\n",
    "    X_train, X_test, y_train, y_test, = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, shuffle=False\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = load_mnist(n_samples=10_000, pca=True, n_components=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953f4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NodeNetwork(16, [8, 8, 8, 8], 1)\n",
    "# nn = NodeNetwork(784, [784, 784, 784], 1)\n",
    "\n",
    "preds_train = nn.predict(X_train)\n",
    "preds_test = nn.predict(X_test)\n",
    "acc_train = accuracy_score(preds_train, y_train)\n",
    "acc_test = accuracy_score(preds_test, y_test)\n",
    "print(f\"Accuracy on training set: {acc_train:.2f}%\")\n",
    "print(f\"Accuracy on test set: {acc_test:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a61c167",
   "metadata": {},
   "source": [
    "## MLP performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab90e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f139d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10_000)\n",
    "clf.fit(X_train, y_train)\n",
    "preds_mlp_train = clf.predict(X_train)\n",
    "preds_mlp_test = clf.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy on training set: {accuracy_score(preds_mlp_train, y_train):.2f}%\")\n",
    "print(f\"Accuracy on test set: {accuracy_score(preds_mlp_test, y_test):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac452dd",
   "metadata": {},
   "source": [
    "## AIG local search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e34e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from cycler import cycler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9d62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\n",
    "    \"axes\",\n",
    "    prop_cycle=(\n",
    "        cycler(\n",
    "            \"color\",\n",
    "            [\n",
    "                \"#1f77b4\",\n",
    "                \"#ff7f0e\",\n",
    "                \"#2ca02c\",\n",
    "                \"#d62728\",\n",
    "                \"#9467bd\",\n",
    "                \"#8c564b\",\n",
    "                \"#e377c2\",\n",
    "                \"#7f7f7f\",\n",
    "                \"#bcbd22\",\n",
    "                \"#17becf\",\n",
    "            ],\n",
    "        )\n",
    "        + cycler(\n",
    "            \"linestyle\",\n",
    "            [\n",
    "                \"solid\",\n",
    "                \"dotted\",\n",
    "                \"dashed\",\n",
    "                \"dashdot\",\n",
    "                (0, (1, 10)),\n",
    "                (0, (5, 10)),\n",
    "                (0, (3, 10, 1, 10)),\n",
    "                (0, (3, 5, 1, 5, 1, 5)),\n",
    "                (0, (1, 1)),\n",
    "                (0, (5, 5)),\n",
    "            ],\n",
    "        )\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef64884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_locs_rec(nn, loc, locs):\n",
    "    if loc[0] == 0 or loc[0] == 1:\n",
    "        return\n",
    "    for parent in nn.nodes_[loc[0]][loc[1]].parents:\n",
    "        if parent[0] != 1 and parent[0] != 0:\n",
    "            locs.append(parent)\n",
    "            append_to_locs_rec(nn, parent, locs)\n",
    "\n",
    "def get_active_nodes(nn):\n",
    "    locs = []\n",
    "    for output_node in nn.nodes_[-1]:\n",
    "        locs.append(output_node.loc)\n",
    "        append_to_locs_rec(nn, output_node.loc, locs)\n",
    "    return list(set(locs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a590ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_parent(nn, loc, idx):\n",
    "    nn_new = copy.deepcopy(nn)\n",
    "    and_node = nn_new.nodes_[loc[0]][loc[1]]\n",
    "    # Get new parent\n",
    "    if len(nn_new.nodes_[and_node.loc[0] - 1]) > 2:\n",
    "        old_parent_loc = and_node.parents.pop(idx)\n",
    "        old_parent = nn_new.nodes_[old_parent_loc[0]][old_parent_loc[1]]\n",
    "        _ = old_parent.children.pop(old_parent.children.index(and_node.loc))\n",
    "        new_parent = random.choice(list(chain(*nn_new.nodes_[:and_node.loc[0]])))\n",
    "        # To prevent from changing nothing or having 2 identical parents\n",
    "        while (new_parent.loc == old_parent_loc) or (new_parent.loc in and_node.parents):\n",
    "            new_parent = random.choice(list(chain(*nn_new.nodes_[:and_node.loc[0]])))\n",
    "        and_node.parents.insert(0, new_parent.loc)\n",
    "        new_parent.children.append(and_node.loc)\n",
    "    return nn_new\n",
    "\n",
    "def change_polarity(nn, loc, idx):\n",
    "    nn_new = copy.deepcopy(nn)\n",
    "    and_node = nn_new.nodes_[loc[0]][loc[1]]\n",
    "    # Change polarity\n",
    "    if idx == 0:\n",
    "        and_node.negate_0 = not and_node.negate_0\n",
    "    elif idx == 1:\n",
    "        and_node.negate_1 = not and_node.negate_1\n",
    "    return nn_new\n",
    "\n",
    "def score(nn, y_train):\n",
    "    preds_train = nn.predict(X_train)\n",
    "    acc = accuracy_score(preds_train, y_train)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e74245",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_hists = []\n",
    "\n",
    "for i in range(10):\n",
    "    nn = NodeNetwork(16, [10] * 24, 1)\n",
    "    patience = 10\n",
    "    acc_hist = []\n",
    "    tol = 0.005\n",
    "\n",
    "    acc_train_best = 0\n",
    "    iteration = 0\n",
    "    no_change = 0\n",
    "\n",
    "    w = widgets.HTML(\n",
    "        value=f\"Iteration {iteration} Accuracy: {acc_train_best}\",\n",
    "        placeholder=\"Iteration progress\",\n",
    "        description=\"\",\n",
    "    )\n",
    "    display(w)\n",
    "\n",
    "    pool = multiprocessing.Pool()\n",
    "\n",
    "    while True:\n",
    "        iteration += 1\n",
    "        successor_candidates = []\n",
    "\n",
    "        locs = get_active_nodes(nn)\n",
    "\n",
    "        tmp = pool.starmap(change_parent, [[nn, loc, 0] for loc in locs])\n",
    "        successor_candidates += tmp\n",
    "\n",
    "        tmp = pool.starmap(change_parent, [[nn, loc, 1] for loc in locs])\n",
    "        successor_candidates += tmp\n",
    "\n",
    "        tmp = pool.starmap(change_polarity, [[nn, loc, 0] for loc in locs])\n",
    "        successor_candidates += tmp\n",
    "\n",
    "        tmp = pool.starmap(change_polarity, [[nn, loc, 1] for loc in locs])\n",
    "        successor_candidates += tmp\n",
    "\n",
    "        accuracies = pool.starmap(score, [[candidate, y_train] for candidate in successor_candidates])\n",
    "\n",
    "        acc_train_current_best = max(accuracies)\n",
    "        acc_hist.append(acc_train_current_best)\n",
    "\n",
    "        if acc_train_current_best > acc_train_best and abs(acc_train_current_best - acc_train_best) > tol:\n",
    "            acc_train_best = acc_train_current_best\n",
    "            nn = copy.deepcopy(successor_candidates[accuracies.index(acc_train_current_best)])\n",
    "            no_change = 0\n",
    "        else:\n",
    "            no_change += 1\n",
    "\n",
    "        if no_change >= patience:\n",
    "            break\n",
    "\n",
    "        w.value = f\"Iteration {iteration} Accuracy: {acc_train_best}\"\n",
    "        \n",
    "    acc_hists.append(acc_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb6eea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc_hists = [acc_hist]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for acc_hist in acc_hists:\n",
    "    ax.plot(acc_hist)\n",
    "    \n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Training accuracies for 10 initializations\\nTolerance 0.005 Patience 10\")\n",
    "ax.grid();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
